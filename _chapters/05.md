# Part II: Distributed Data

# Ch 5: Replication

## Intro

WHY:
1. Geo proximity to users
2. fail-safe -> increases __availability__ 
3. scale out -> increase __throughput__
Types:
- single-leader
- multi-leader
- leaderless
> Synchronous VS Async

## Leaders and Followers

> aka active/passive OR master-slave replication
Used in: 
- DBs: PostreSQL, MySQL as well  as MongoDB, etc etc
- Non DBs: Kafka, RabbitMQ

### Synchronous vs. asynchronous replication

- `Synchronous` generally means __one__ of the followers is only synced, since it is impractical to make all followers to sync as it will halt the system. It is then often called `semi-synchronous`
- Often thought, replication is `async` -> WRITES are not guaranteed to be durable, but writes are not slowed down by replication
- `chain replication` - sync replication with good performance ( used in MS Azure)

### Setting up new followers

Steps:
1. take snapshot (built in feature often, for MySQL use _innobackupex_)
2. copy snapshot to the follewer
3. update follower with a newer data after snapshot's exact pos in replication log ( aka `log sequence number` in PostgreSQL, `binlog coordinates` in MySQL )
4. confirm it `caught up`

### Handling node outages

1. Follower failure: catch-up recovery
	- follower recovers from it's `log`, which points to the last transaction processed and can copy newer data from the leader
2. Leader failure: `Failover`
	1. Determine Leader has Failed
		1. nodes bounce messages between each other
	2. Choose new leader
		1. make all nodes agree on a new leader(`consensus problem`)
		2. ideally new leader needs to have most up-to-date data
	3. Reconfigure the system to use new leader
		1. Ensure old leader becomes a follower after recovery
		ISSUES:
			- async replication looses leaders newest writes
			- may cause issues on depndent systems - i.e. GitHub MySQL-Redis issue
			- `split brain` issue - both leaders accept writes
			- Timeout time - Time for recovery VS False positives (during peak load)

> Perform Failovers manually to minimise issues

### Implementation of replication logs

#### 1. Statement-based replication
	- Leader's log sent to all followers (it includes ever WRITE request (statement) - INSERT, UPDATE, DELETE for relational DB) so they can execute these statements themselves
	- Issues:
			1. `nondetermenistic` functions generate diff values - i.e. RAND(), NOW()
			2. `autoincrement` - should be in the same order on each replica
			3. `side effects` of statements (i.e. triggers, stored procedures, user-defined functions) 
#### 2. Write-ahead log (WAL) shipping

	- append only log. In case of B-trees data is writtten into WAL then onto B-tree index
	- used in PostgreSQL, Oracle
	- Disadvantage: 
		- very low level representation of data -> replication is closely coupled with storage engine
		- hence can't have leaders and followers on different DB versions
#### 3. Logical (row-based) log replication
		Contains
			- for inserts - new values
			- for deletions - data to id the row (PrimaryKey or values)
			- for updates - data to id the row + new values
		Used in MySQL `binlog` when configured to use _row-based_ replication
		Advantage:
			- decoupled from storage engine and can be backwards compatible or even use different storage engines
			- easier to use with external apps. Refer `change data captuer` Ch11
#### 4. Trigger-based replication

Unlike previous algos - it is defined in App and gives felixbility (i.e. Conflict Resolution, replicate only certain subsets of data)
Use built-in RDB features: `Triggers` and `Stored Procedures`: 
	exec custom code on WRITE transaction. Can log change into a separate table (i.e. `Bucardo` for Postgres) 

## Problems With Replication Lag

### 1.Reading your own writes

### 2. Monotonic reads

### 3. Consistent prefix reads

### 4. Solutions for replication lag

## Multi-leader replication

### Use cases for multi-leader replication

### Handling write conflicts

### Multi-leader replication topologies

## Leaderless replication

### Writing to the database when a node is down

### Limitations of quorum consistency

### Sloppy quorums and hinted handoff

### Detecting concurrent writes
